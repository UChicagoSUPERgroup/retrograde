{"cells": [{"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["# Introduction\n", "\n", "Thank you for agreeing to take part in this evaluation. During this evaluation you will be asked to carry out a series of tasks related to the dataset shown in the next section. Please carry out these tasks with the same care and rigor as if these tasks were part of your job duties.\n", "    \n", "Before beginning please ensure that you are using the prompter kernel by looking at the top right of this notebook. It should say \"prompter\", rather than \"Python 3\". If says you are using a python kernel, please click on where it says Python, and select the prompter from the drop down study. If you encounter any errors, or if it says \"No Kernel!\" please contact [PLACEHOLDER@uchicago.edu](PLACEHOLDER@uchicago.edu) so we can fix the issue.\n"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["## Task Description\n", "\n", "This task is structured into four parts.\n", "\n", "1. **Dataset introduction**\n", "2. **Data cleaning**\n", "3. **Model Training**\n", "4. **Model Selection**\n", "\n", "In each of these, there will be some code pre-written. This code is meant to help you complete the task by providing structure, but you are not required to use the provided code if you do not want to. You may refer to any documentation source you like during this task (such as StackOverflow, or Pandas API documentation or tutorials).\n", "\n", "We ask that you use pandas and scikit-learn to perform the tasks. We have also installed numpy and matplotlib, should those be helpful. You will not be able to install any other non-standard libraries."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["## 1. Dataset Introduction\n", "\n"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["We will be asking you to use the provided \"loan&#95;data.csv\" dataset during this experiment. This data was collected in a major metropolitan city in the United States. It contains information about applications for loans recieved by several different loan providers.\n", "\n", "Let's start trying to understand the dataset by writing some python code. Feel free to follow along by running the following sample commands in this notebook.\n", "\n", "Below is a few lines of python code that loads the provided \"loan&#95;data.csv\" dataset into a pandas dataframe."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>race</th>\n", "      <th>gender</th>\n", "      <th>date</th>\n", "      <th>zip</th>\n", "      <th>income</th>\n", "      <th>type</th>\n", "      <th>term</th>\n", "      <th>interest</th>\n", "      <th>principal</th>\n", "      <th>approved</th>\n", "      <th>adj_bls_2</th>\n", "      <th>id</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>hispanic/latino</td>\n", "      <td>male</td>\n", "      <td>2016-01-01</td>\n", "      <td>60623.0</td>\n", "      <td>72230.0</td>\n", "      <td>home</td>\n", "      <td>180</td>\n", "      <td>3.389672</td>\n", "      <td>508761</td>\n", "      <td>False</td>\n", "      <td>0.34</td>\n", "      <td>AP20161-0-2</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>other</td>\n", "      <td>male</td>\n", "      <td>2013-03-01</td>\n", "      <td>60625.0</td>\n", "      <td>18543.0</td>\n", "      <td>home</td>\n", "      <td>360</td>\n", "      <td>0.277318</td>\n", "      <td>119738</td>\n", "      <td>False</td>\n", "      <td>0.14</td>\n", "      <td>AP20133-1-23</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>other</td>\n", "      <td>male</td>\n", "      <td>2011-11-01</td>\n", "      <td>60623.0</td>\n", "      <td>30228.0</td>\n", "      <td>home</td>\n", "      <td>240</td>\n", "      <td>4.398939</td>\n", "      <td>265779</td>\n", "      <td>False</td>\n", "      <td>0.08</td>\n", "      <td>AP201111-2-22</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>hispanic/latino</td>\n", "      <td>male</td>\n", "      <td>2014-08-01</td>\n", "      <td>60623.0</td>\n", "      <td>11129.0</td>\n", "      <td>personal</td>\n", "      <td>60</td>\n", "      <td>5.221935</td>\n", "      <td>15590</td>\n", "      <td>True</td>\n", "      <td>0.09</td>\n", "      <td>AP20148-1-29</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>black</td>\n", "      <td>female</td>\n", "      <td>2016-11-01</td>\n", "      <td>60637.0</td>\n", "      <td>NaN</td>\n", "      <td>personal</td>\n", "      <td>60</td>\n", "      <td>10.843707</td>\n", "      <td>56301</td>\n", "      <td>True</td>\n", "      <td>0.41</td>\n", "      <td>AP201611-0-38</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["              race  gender        date      zip   income      type  term  \\\n", "0  hispanic/latino    male  2016-01-01  60623.0  72230.0      home   180   \n", "1            other    male  2013-03-01  60625.0  18543.0      home   360   \n", "2            other    male  2011-11-01  60623.0  30228.0      home   240   \n", "3  hispanic/latino    male  2014-08-01  60623.0  11129.0  personal    60   \n", "4            black  female  2016-11-01  60637.0      NaN  personal    60   \n", "\n", "    interest  principal  approved  adj_bls_2             id  \n", "0   3.389672     508761     False       0.34    AP20161-0-2  \n", "1   0.277318     119738     False       0.14   AP20133-1-23  \n", "2   4.398939     265779     False       0.08  AP201111-2-22  \n", "3   5.221935      15590      True       0.09   AP20148-1-29  \n", "4  10.843707      56301      True       0.41  AP201611-0-38  "]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["import pandas as pd\n", "\n", "loans = pd.read_csv(\"loan_data.csv\")\n", "loans.head()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["We can get a list of the columns in this dataframe with the following command"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/plain": ["Index(['race', 'gender', 'date', 'zip', 'income', 'type', 'term', 'interest',\n", "       'principal', 'approved', 'adj_bls_2', 'id'],\n", "      dtype='object')"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["loans.columns"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Let's look at some of the columns in the dataframe. The column ``approved`` indicates whether or not the loan was approved"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.43152257077276207"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["# since python treats True as a 1, and False as a 0, the sum\n", "# of this array is the number of entries in loans where approved == True\n", "\n", "sum(loans[\"approved\"])/len(loans[\"approved\"]) # calculating the fraction of approved loans"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["The column ``principal`` is the amount of money the loan was for, that is how much money the applicant received if the loan was approved."]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["16150.0 375306.0\n"]}], "source": ["# 25th and 75th percentile\n", "print(loans[\"principal\"].quantile(0.25), loans[\"principal\"].quantile(0.75))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["That's a fairly wide variation in loan amounts. One possible reason for this is that there are different purposes for which the loans were applied for. The ``type`` column denotes the purpose of the loan. "]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/plain": ["array(['home', 'personal', 'auto'], dtype=object)"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["loans[\"type\"].unique()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["There are three possible values ``type`` can have: ``personal``, ``home`` and ``auto``. \n", "\n", "* ``auto`` These loans were for automobile purchases. With these loans, the lender may repossess the car if the person who took out the loan is unable to make payments.\n", "\n", "* ``home`` These loans were for the purchase of residential real estate. Under these loans, the lender may reposssess the home through foreclosure if the person who took out the loan is unable to make payments.\n", "\n", "* ``personal`` These loans are for personal expenses or investments other than a home or automobile. Under these loans, there is not generally any specific piece of property that a lender may repossess."]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Personal loans: 0.25172149961744456\n", "Home loans: 0.3802601377199694\n", "Auto loans: 0.3680183626625861\n", "\n"]}], "source": ["# here we use the same trick we used to calculate the approval rate \n", "# to calculate the different types of loans. \n", "\n", "personal_pct = sum(loans[\"type\"] == \"personal\")/len(loans[\"type\"])\n", "\n", "# Since the 'type' column is a string, the statement \n", "# loans[\"type\"] == \"personal\" produces a #Series of True/False values \n", "# indicating for each entry in the 'type' column whether it equals \"personal\"\n", "# or not\n", "\n", "home_pct = sum(loans[\"type\"] == \"home\")/len(loans[\"type\"])\n", "auto_pct = sum(loans[\"type\"] == \"auto\")/len(loans[\"type\"])\n", "\n", "print(\"Personal loans: {0}\\nHome loans: {1}\\nAuto loans: {2}\\n\".format(personal_pct, home_pct, auto_pct))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["``interest`` is the annual percent interest on the loan. ``term`` is how long in months the loan was supposed to run. \n", "\n", "``income`` is the annual income of the loan applicants."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["# Your Turn\n", "\n", "At the end of the next sections, there will be space like this where we will ask you to complete certain tasks. \n", "\n", "There's nothing that you need to do right now. However if you want to examine any of the columns in more depth this is a good spot to do so. "]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# This is where you will write python code. Execute these cells using the\n", "# play button or the keyboard shortcut to execute cells."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["## 2. Data Cleaning\n", "\n", "Before we can use this data to build a model, we'll need to clean it up a bit. Suppose we wanted to look at loans issued between certain dates. How would we do that?"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": ["dtype('O')"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["loans[\"date\"].dtypes # this tells us the type of entries in the date column"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["``dtype('0')`` means that pandas thinks that the dates are generic objects (strings, in this case), as opposed to dates. "]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/plain": ["str"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["type(loans[\"date\"][0])"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Because of the way Pandas works with csv files, this is interpreted as a string. In order do things like test whether a loan was issued before or after a certain date, we need to convert it to a different type."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/plain": ["pandas._libs.tslibs.timestamps.Timestamp"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["loans[\"date\"] = pd.to_datetime(loans[\"date\"])\n", "type(loans[\"date\"][0])"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Now we can easily find out how many applications there were from 2015 on using the same trick we used to get the proportion of different types of loans in the previous section."]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/plain": ["838"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["from datetime import datetime\n", "\n", "sum(loans[\"date\"] >= datetime(month=1, day=1, year=2015))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### 2a. Categorical data\n", "Another thing we need to do is to deal with data that is categorical (not numeric and which does not have any sort of ordering). Since many scikit-learn models can only handle data that is numeric, it is necessary to represent these columns numerically.\n", "\n", "One example of this is the ``type`` column. To turn this into numeric data, we'll apply a dummy encoding. "]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>type_home</th>\n", "      <th>type_personal</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>1</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>1</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>1</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>0</td>\n", "      <td>1</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>0</td>\n", "      <td>1</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["   type_home  type_personal\n", "0          1              0\n", "1          1              0\n", "2          1              0\n", "3          0              1\n", "4          0              1"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["# this encodes the type column of loans using a dummy coding\n", "coded_cols = pd.get_dummies(loans[\"type\"], \n", "                            prefix=\"type\", # this sets the column names as type_<var_name>\n", "                            drop_first=True) # we'll explain what this does below\n", "\n", "coded_cols.head()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Each row in this dataframe indicates whether the type was ``home`` or ``personal``.\n", "\n", "Maybe you've noticed that there are only two columns in this dataframe. That's because we set the ``drop_first`` argument in the ``get_dummies`` function to ``True``. Since there were three possible values for loan type, we know that any entry that has a 0 in both the ``type_home`` and ``type_personal`` columns is of type ``auto``.\n", "\n", "Why don't we also have a column indicating whether the loan is an auto loan or not? In some types of model, having a redundant column like that can cause problems. \n", "\n", "Now we need to attach these dummy columns back to our original data."]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>race</th>\n", "      <th>gender</th>\n", "      <th>date</th>\n", "      <th>zip</th>\n", "      <th>income</th>\n", "      <th>term</th>\n", "      <th>interest</th>\n", "      <th>principal</th>\n", "      <th>approved</th>\n", "      <th>adj_bls_2</th>\n", "      <th>id</th>\n", "      <th>type_home</th>\n", "      <th>type_personal</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>hispanic/latino</td>\n", "      <td>male</td>\n", "      <td>2016-01-01</td>\n", "      <td>60623.0</td>\n", "      <td>72230.0</td>\n", "      <td>180</td>\n", "      <td>3.389672</td>\n", "      <td>508761</td>\n", "      <td>False</td>\n", "      <td>0.34</td>\n", "      <td>AP20161-0-2</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>other</td>\n", "      <td>male</td>\n", "      <td>2013-03-01</td>\n", "      <td>60625.0</td>\n", "      <td>18543.0</td>\n", "      <td>360</td>\n", "      <td>0.277318</td>\n", "      <td>119738</td>\n", "      <td>False</td>\n", "      <td>0.14</td>\n", "      <td>AP20133-1-23</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>other</td>\n", "      <td>male</td>\n", "      <td>2011-11-01</td>\n", "      <td>60623.0</td>\n", "      <td>30228.0</td>\n", "      <td>240</td>\n", "      <td>4.398939</td>\n", "      <td>265779</td>\n", "      <td>False</td>\n", "      <td>0.08</td>\n", "      <td>AP201111-2-22</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>hispanic/latino</td>\n", "      <td>male</td>\n", "      <td>2014-08-01</td>\n", "      <td>60623.0</td>\n", "      <td>11129.0</td>\n", "      <td>60</td>\n", "      <td>5.221935</td>\n", "      <td>15590</td>\n", "      <td>True</td>\n", "      <td>0.09</td>\n", "      <td>AP20148-1-29</td>\n", "      <td>0</td>\n", "      <td>1</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>black</td>\n", "      <td>female</td>\n", "      <td>2016-11-01</td>\n", "      <td>60637.0</td>\n", "      <td>NaN</td>\n", "      <td>60</td>\n", "      <td>10.843707</td>\n", "      <td>56301</td>\n", "      <td>True</td>\n", "      <td>0.41</td>\n", "      <td>AP201611-0-38</td>\n", "      <td>0</td>\n", "      <td>1</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["              race  gender       date      zip   income  term   interest  \\\n", "0  hispanic/latino    male 2016-01-01  60623.0  72230.0   180   3.389672   \n", "1            other    male 2013-03-01  60625.0  18543.0   360   0.277318   \n", "2            other    male 2011-11-01  60623.0  30228.0   240   4.398939   \n", "3  hispanic/latino    male 2014-08-01  60623.0  11129.0    60   5.221935   \n", "4            black  female 2016-11-01  60637.0      NaN    60  10.843707   \n", "\n", "   principal  approved  adj_bls_2             id  type_home  type_personal  \n", "0     508761     False       0.34    AP20161-0-2          1              0  \n", "1     119738     False       0.14   AP20133-1-23          1              0  \n", "2     265779     False       0.08  AP201111-2-22          1              0  \n", "3      15590      True       0.09   AP20148-1-29          0              1  \n", "4      56301      True       0.41  AP201611-0-38          0              1  "]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["# this attaches the coded columns \"to the side\" of loans\n", "encoded_loans = pd.concat([loans, coded_cols], axis=1) \n", "\n", "# but loans still contains the \"type\" column so we drop that \n", "# to keep things neat\n", "loans = encoded_loans.drop([\"type\"], axis=1)\n", "loans.head()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### 2b. Null data\n", "\n", "Several columns contain null data. This means that the information was not recorded by the loan officer at the time of the application. This may be a problem as many machine learning models cannot handle undefined input or output values.\n", "\n", "There are several methods of handling null data. One option is to drop all rows where the entry is not defined. "]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["1307 998\n"]}], "source": ["all_dropped = loans.dropna()\n", "print(len(loans), len(all_dropped))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["As you can see, this removed a significant number of entries. Doing this makes the data much easier to use, but may introduce systematic errors if the data is not missing in a purely random fashion."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Another option is to drop just the columns where there is a null entry. "]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["['race', 'gender', 'zip', 'income']\n"]}], "source": ["cols_dropped = loans.dropna(axis=\"columns\")\n", "\n", "# which columns are removed this way?\n", "missing = [l for l in loans.columns if l not in cols_dropped.columns]\n", "\n", "print(missing)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["This preserved the number of entries, but means that we're missing possibly important columns like ``income``"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["You can also try to attribute a value to data in a column that's missing. Here for example, we fill the missing entries in the ``income`` column with 0.  "]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"data": {"text/plain": ["0    72230.0\n", "1    18543.0\n", "2    30228.0\n", "3    11129.0\n", "4        0.0\n", "Name: income, dtype: float64"]}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": ["filled_interest = loans[\"income\"].fillna(0.0)\n", "filled_interest.head()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["# Your Turn\n", "\n", "There are two things you need to do here \n", "\n", "1. Handle the missing data in the \"loan_data.csv\". We suggest that you do this first as it may impact how you handle encoding the types of the data. \n", "\n", "2. Look through the columns and encode data into the correct type. A helpful command to see the type of each of the columns in the dataframe is shown below."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["When completing both 1 & 2, you are free to use any method mentioned here. If you want to use a technique or method not mentioned here, you are also free to do so. You are also free to revisit this or any other section at any time.\n", "\n", "**Remember**, when completeing the tasks try to treat them as if they are part of your job, and it is your responsibility to create an effective model for predicting loan acceptance. "]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["['race', 'gender', 'zip', 'income']\n", "309\n"]}], "source": ["#write your code here to perform part 1 of the task. Below is a small\n", "#code snippet to help you get started. You may delete the snippet\n", "#if you wish.\n", "\n", "import pandas as pd\n", "\n", "def handle_nulls(loans_dataframe):\n", "    '''function for cleaning '''\n", "    # this just prints the columns with nulls\n", "    cols_with_nulls = [c for c in loans_dataframe.columns if loans_dataframe[c].isna().any()]\n", "    print(cols_with_nulls)\n", "    \n", "    # this just prints the number of rows with null data in any entry\n", "    rows_with_nulls = loans_dataframe.isna().any(axis=1)\n", "    \n", "    # loans_dataframe.isna() produces a dataframe of the same size and \n", "    # shape as loans_dataframe, but with True/False in each entry indicating\n", "    # whether each entry is null or not. \n", "    \n", "    # .any checks if any of the entries are true, with the axis argument set to \n", "    # 1, this means that it checks for each row in loans_dataframe.any() if there is \n", "    # an entry with True in it\n", "    \n", "    print(sum(rows_with_nulls))\n", "    \n", "    # Now you should do something to the data\n", "    \n", "    return loans_dataframe\n", "        \n", "cleaned_nulls = handle_nulls(pd.read_csv(\"loan_data.csv\"))\n", "   "]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["['race', 'gender', 'zip', 'income']\n", "309\n", "race          object\n", "gender        object\n", "date          object\n", "zip          float64\n", "income       float64\n", "type          object\n", "term           int64\n", "interest     float64\n", "principal      int64\n", "approved        bool\n", "adj_bls_2    float64\n", "id            object\n", "dtype: object\n"]}], "source": ["#write your code here to perform part 2 of the task\n", "#Below is a small code snippet to help you get started,\n", "#you may delete the snippet if you wish\n", "\n", "def encode_data(cleaned_loans_dataframe):\n", "        print(cleaned_loans_dataframe.dtypes)\n", "        #do something\n", "        return cleaned_loans_dataframe\n", "        \n", "cleaned_loans = handle_nulls(pd.read_csv(\"loan_data.csv\"))        \n", "cleaned_data = encode_data(cleaned_loans)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["## 3. Model Training"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["**Do not uncomment the following line of code. Make Sure to run the following line of code as is.** This tells the plugin that you have reached the stage where you are starting to build models. "]}, {"cell_type": "code", "execution_count": 6, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# %prompter_plugin model_training%"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Executing this block does not prevent you from going back and revisiting previous data analysis decisions. "]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["In section 4, we will ask you to train a classifier which predicts whether a loan will be approved or not. The purpose of this classifier is to be used by loan officers or local lenders to recommend to applicants specific loans they might be eligible for. The lenders hope that this tool will help match financial products to borrowers more efficiently. \n", "\n", "Please note that this classifier be used to make *recommendations* and **not** decisions about whether to grant a loan or not. \n", "\n", "There are a couple different things you could do here. A small example using the ``LogisticRegression`` is included below. "]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.4312977099236641"]}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": ["from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "\n", "X = loans[[\"type_home\", \"type_personal\", \"principal\", \"interest\"]]\n", "y = loans[\"approved\"]\n", "\n", "# this creates training and testing sets \n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n", "\n", "lr = LogisticRegression()\n", "lr.fit(X_train,y_train) # this \"fits\" or \"trains\" the model using X and y as training data\n", "\n", "# this is the predictions for what y should be. \n", "# they may be helpful if you want to understand more about what a model is doing\n", "preds = lr.predict(X_test)\n", "\n", "lr.score(X_test, y_test)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["How well does the regression we built work? Is an accuracy of 0.43 good or bad in this case? If you followed along from the start, you might recall that the approval rate in our data was about 0.43 as well. \n", "\n", "This suggests the possibility that ``lr`` is predicting ``True`` no matter what."]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": 30, "metadata": {}, "output_type": "execute_result"}], "source": ["preds.all() # this tests whether all the predictions are True"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["So it turns out that ``lr`` doesn't work very well. In fact, if we had a model that guessed ``False`` all the time, that the loan would not be approved, it would have an accuracy of 0.57!"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["We can likely improve upon this baseline. In the next **Your Turn** we will ask you to explore some of the ways in which might improve the classification performance. "]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["# Your Turn\n", "\n", "Use the data you cleaned up in section 2 to build your own Logistic Regression. In the regression we built above, we just used a few columns. Try different combinations of columns to see if that changes the results you get. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def choose_columns(cleaned_data):\n", "    # write code here\n", "    return cleaned_data\n", "\n", "X = choose_columns(cleaned_data)\n", "y = cleaned_data[\"approved\"] # change this if you've renamed the `approved` column\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n", "lr = LogisticRegression()\n", "lr.fit(X_train,y_train)\n", "lr.score(X_test, y_test)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["You can also try changing the type of model that you're using. In the example above, we just used the LogisticRegression classifier. Do you get different results if you use a different type of classifier?\n", "\n", "There are other types of classifiers in scikit-learn, like the KNeighborsClassifier, or the DecisionTreeClassifier. If you are not familiar with these, don't worry. They all may be trained using the same calls to ``fit``, ``score`` and ``predict``."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "\n", "dt = DecisionTreeClassifier()\n", "knn = KNeighborsClassifier()\n", "lr = LogisticRegression()\n", "\n", "X = choose_columns(cleaned_data)\n", "y = cleaned_data[\"approved\"]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n", "\n", "dt.fit(X_train, y_train)\n", "knn.fit(X_train, y_train)\n", "lr.fit(X_train, y_train)\n", "\n", "print(lr.score(X_test, y_test), dt.fit(X_test, y_test), knn.fit(X_test, y_test))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["# End\n", "\n", "Thank you for participating in the study. In section 3 you should have explored the performance of several different classifiers. Now is the time where you need to choose which one you believe to be the best. To submit your model for consideration, please assign your model to the variable SUBMITTED_MODEL in the cell below. Then execute the submission cell below that one. \n", "\n", "Remember that the model you submit will be used to recommend financial products to prospective loan applicants. \n", "\n", "You may submit multiple times, however only your last submitted model will be considered."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SUBMITTED_MODEL = # write the variable here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# %prompter_plugin submit %"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["You may now return to the Qualtrics and complete the survey."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.5"}}, "nbformat": 4, "nbformat_minor": 4}