{"cells": [{"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["# Introduction\n", "\n", "Thank you for agreeing to take part in this evaluation. During this evaluation you will be asked to carry out a series of tasks related to the dataset shown in the next section. Please carry out these tasks with the same care and rigor as if these tasks were part of your job duties.\n", "    \n", "Before beginning please ensure that you are using the prompter kernel by looking at the top right of this notebook. It should say \"prompter\", rather than \"Python 3\". If says you are using a python kernel, please click on where it says Python, and select the prompter from the drop down study. If you encounter any errors, or if it says \"No Kernel!\" please contact [PLACEHOLDER@uchicago.edu](PLACEHOLDER@uchicago.edu) so we can fix the issue.\n"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["## Task Description\n", "\n", "This task is structured into four parts.\n", "\n", "1. **Dataset introduction**\n", "2. **Data cleaning**\n", "3. **Model Training**\n", "4. **Model Selection**\n", "\n", "In each of these four sections, there is a tutorial portion and a task portion.\n", "The tutorial portions are meant to provide background and structure to the task, and may be helpful to you when completing the tasks.\n", "You will know that you have reached a task portion because we will mark them <span style=\"color:red\"> **in red** </span>\n", "\n", "In each of these, there will be some code pre-written. This code is meant to help you complete the task by providing structure, but you are not required to use the provided code if you do not want to. You may refer to any documentation source you like during this task (such as StackOverflow, or Pandas API documentation or tutorials).\n", "\n", "We ask that you use pandas and scikit-learn to perform the tasks. We have also installed numpy and matplotlib, should those be helpful. You will not be able to install any other non-standard libraries."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["## 1. Dataset Introduction\n", "\n"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["We will be asking you to use the provided \"loan&#95;data.csv\" dataset during this experiment. This data was collected in a major metropolitan city in the United States. It contains information about applications for loans recieved by several different loan providers.\n", "\n", "Let's start trying to understand the dataset by writing some python code. Feel free to follow along by running the following sample commands in this notebook.  \n", "\n", "Below is a few lines of python code that loads the provided \"loan&#95;data.csv\" dataset into a pandas dataframe."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "\n", "loans = pd.read_csv(\"loan_data.csv\", parse_dates=[\"date\"])\n", "loans.head()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["We can get a list of the columns in this dataframe with the following command"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loans.columns"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Let's look at some of the columns in the dataframe. The column ``approved`` indicates whether or not the loan was approved"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# since python treats True as a 1, and False as a 0, the sum\n", "# of this array is the number of entries in loans where approved == True\n", "\n", "sum(loans[\"approved\"])/len(loans[\"approved\"]) # calculating the fraction of approved loans"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["The column ``principal`` is the amount of money the loan was for, that is how much money the applicant received if the loan was approved."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 25th and 75th percentile\n", "print(loans[\"principal\"].quantile(0.25), loans[\"principal\"].quantile(0.75))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["That's a fairly wide variation in loan amounts. One possible reason for this is that there are different purposes for which the loans were applied for. The ``type`` column denotes the purpose of the loan. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loans[\"type\"].unique()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["There are three possible values ``type`` can have: ``personal``, ``home`` and ``auto``. \n", "\n", "* ``auto`` These loans were for automobile purchases. With these loans, the lender may repossess the car if the person who took out the loan is unable to make payments.\n", "\n", "* ``home`` These loans were for the purchase of residential real estate. Under these loans, the lender may reposssess the home through foreclosure if the person who took out the loan is unable to make payments.\n", "\n", "* ``personal`` These loans are for personal expenses or investments other than a home or automobile. Under these loans, there is not generally any specific piece of property that a lender may repossess."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# here we use the same trick we used to calculate the approval rate \n", "# to calculate the different types of loans. \n", "\n", "personal_pct = sum(loans[\"type\"] == \"personal\")/len(loans[\"type\"])\n", "\n", "# Since the 'type' column is a string, the statement \n", "# loans[\"type\"] == \"personal\" produces a #Series of True/False values \n", "# indicating for each entry in the 'type' column whether it equals \"personal\"\n", "# or not\n", "\n", "home_pct = sum(loans[\"type\"] == \"home\")/len(loans[\"type\"])\n", "auto_pct = sum(loans[\"type\"] == \"auto\")/len(loans[\"type\"])\n", "\n", "print(\"Personal loans: {0}\\nHome loans: {1}\\nAuto loans: {2}\\n\".format(personal_pct, home_pct, auto_pct))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["``interest`` is the annual percent interest on the loan. ``term`` is how long in months the loan was supposed to run. \n", "\n", "``income`` is the annual income of the loan applicants."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### <span style=\"color:red\">Your Turn</span>\n", "\n", "Section 1 is just an introduction to the dataset you will be using. There's no specific task for you to do in this section. However, you should have a sense of what this data is and where it comes from before proceeding.\n", "\n", "In the next section, you will be asked to make certain decisions about how to clean this data and get it into a usable form."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["## 2. Data Cleaning\n", "\n", "Before we can use this data to build a model, we'll need to clean it up a bit. There are two problems with this data. It is missing values in some entries and certain variables are not in a form that can be used to build a model.\n", "\n", "There are two <span style=\"color:red\">**Your Turn**</span> sections in this part. You will likely find it convenient to start with the first and go on to the second. You may also find it useful to revisit your work in these sections as you move on to the model building tasks in section 3."]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### 2a. Missing data\n", "\n", "Several columns contain null data. This means that the information was not recorded by the loan officer at the time of the application. This may be a problem as many machine learning models cannot handle undefined input or output values.\n", "\n", "There are several methods of handling null data. One option is to drop all rows where the entry is not defined. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_dropped = loans.dropna()\n", "print(len(loans), len(all_dropped))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["As you can see, this removed a significant number of entries. Doing this makes the data much easier to use, but may introduce systematic errors if the data is not missing in a purely random fashion. For example:\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "true_data = np.array([10, 40, 36, 12, 67])\n", "missing_data_lower = np.array([np.nan, 40, 36, np.nan, 67]) # lower values are missing\n", "missing_data_upper = np.array([10, np.nan, 36, 12, np.nan]) # upper values are missing\n", "print(np.nanmean(missing_data_upper), np.nanmean(missing_data_lower)) # nanmean computes the mean, but ignores nan or missing data\n"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Another option is to drop just the columns where there is a null entry. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cols_dropped = loans.dropna(axis=\"columns\")\n", "\n", "# which columns are removed this way?\n", "missing = [l for l in loans.columns if l not in cols_dropped.columns]\n", "\n", "print(missing)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["This preserved the number of entries, but means that we're missing possibly important columns like ``income``"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["You can also try to attribute a value to data in a column that's missing. Here for example, we fill the missing entries in the ``income`` column with 0.  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["filled_interest = loans[\"income\"].fillna(0.0)\n", "filled_interest.head()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### <span style=\"color:red\">Your Turn Part 1</span>\n", "\n", "Handle the missing data in the \"loan_data.csv\". We suggest that you do this first as it may impact how you handle encoding the types of the data in the second part of this section.\n", "\n", "You are free to use any method mentioned here. If you want to use a technique or method not mentioned here, you are also free to do so. You are also free to revisit this or any other section at any time.\n", "\n", "**Remember**, when completing the tasks try to treat them as if they are part of your job, and it is your responsibility to create an effective model for predicting loan acceptance. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#write your code here to perform part 1 of the task. Below is a small\n", "#code snippet to help you get started. You may delete the snippet\n", "#if you wish.\n", "\n", "import pandas as pd\n", "\n", "def handle_nulls(loans_dataframe):\n", "    '''function for cleaning '''\n", "    # this just prints the columns with nulls\n", "    cols_with_nulls = [c for c in loans_dataframe.columns if loans_dataframe[c].isna().any()]\n", "    print(cols_with_nulls)\n", "    \n", "    # this just prints the number of rows with null data in any entry\n", "    rows_with_nulls = loans_dataframe.isna().any(axis=1)\n", "    \n", "    # loans_dataframe.isna() produces a dataframe of the same size and \n", "    # shape as loans_dataframe, but with True/False in each entry indicating\n", "    # whether each entry is null or not. \n", "    \n", "    # .any checks if any of the entries are true, with the axis argument set to \n", "    # 1, this means that it checks for each row in loans_dataframe.any() if there is \n", "    # an entry with True in it\n", "    \n", "    print(sum(rows_with_nulls))\n", "    \n", "    # Now you should do something to the data\n", "    \n", "    return loans_dataframe\n", "        \n", "cleaned_nulls = handle_nulls(pd.read_csv(\"loan_data.csv\", parse_dates=[\"date\"]))\n", "   "]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### 2b. Categorical data\n", "Another thing we need to do is to deal with data that is categorical (not numeric and which does not have any sort of ordering). Since many scikit-learn models can only handle data that is numeric, it is necessary to represent these columns numerically.\n", "\n", "One example of this is the ``type`` column. To turn this into numeric data, we'll apply a dummy encoding. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# this encodes the type column of loans using a dummy coding\n", "coded_cols = pd.get_dummies(loans[\"type\"], \n", "                            prefix=\"type\", # this sets the column names as type_<var_name>\n", "                            drop_first=True) # we'll explain what this does below\n", "\n", "coded_cols.head()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Each row in this dataframe indicates whether the type was ``home`` or ``personal``.\n", "\n", "Maybe you've noticed that there are only two columns in this dataframe. That's because we set the ``drop_first`` argument in the ``get_dummies`` function to ``True``. Since there were three possible values for loan type, we know that any entry that has a 0 in both the ``type_home`` and ``type_personal`` columns is of type ``auto``.\n", "\n", "Why don't we also have a column indicating whether the loan is an auto loan or not? In some types of model, having a redundant column like that can cause problems. \n", "\n", "Now we need to attach these dummy columns back to our original data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# this attaches the coded columns \"to the side\" of loans\n", "encoded_loans = pd.concat([loans, coded_cols], axis=1) \n", "\n", "# but loans still contains the \"type\" column so we drop that \n", "# to keep things neat\n", "loans = encoded_loans.drop([\"type\"], axis=1)\n", "loans.head()"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### <span style=\"color:red\">Your Turn Part 2</span>\n", "\n", "\n", "Look through the columns and encode data into the correct type. The ``encode_data`` function shown below lists the types of the columns. Note that certain python types (such as strings) are listed as ``object``. \n", "\n", "You are free to use any method mentioned here. If you want to use a technique or method not mentioned here, you are also free to do so. You are also free to revisit this or any other section at any time.\n", "\n", "**Remember**, when completing the tasks try to treat them as if they are part of your job, and it is your responsibility to create an effective model for predicting loan acceptance. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#write your code here to perform part 2 of the task\n", "#Below is a small code snippet to help you get started,\n", "#you may delete the snippet if you wish\n", "\n", "def encode_data(cleaned_loans_dataframe):\n", "        print(cleaned_loans_dataframe.dtypes)\n", "        #do something\n", "        return cleaned_loans_dataframe\n", "        \n", "cleaned_loans = handle_nulls(pd.read_csv(\"loan_data.csv\", parse_dates=[\"date\"]))        \n", "cleaned_data = encode_data(cleaned_loans)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["## 3. Model Training"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["In this section, we will ask you to train a classifier which predicts whether a loan will be approved or not. The purpose of this classifier is to be used by loan officers or local lenders to recommend to applicants specific loans they might be eligible for. The lenders hope that this tool will help match financial products to borrowers more efficiently. \n", "\n", "Please note that this classifier be used to make *recommendations* and **not** decisions about whether to grant a loan or not. \n", "\n", "In this part, there are two <span style=\"color:red\">**Your Turn**</span> sections. In the first, you will be asked to select features to use. In the second, you will be asked to select different model architectures. While we suggest completing the first one, and then moving on to the second one, and then revisiting the first and any other previous steps as necessary. \n", "\n", "There are a couple different things you could do here. A small example using the ``LogisticRegression`` is included below. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "\n", "X = loans[[\"type_home\", \"type_personal\", \"principal\", \"interest\"]]\n", "y = loans[\"approved\"]\n", "\n", "# this creates training and testing sets \n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n", "\n", "lr = LogisticRegression()\n", "lr.fit(X_train,y_train) # this \"fits\" or \"trains\" the model using X and y as training data\n", "\n", "# this is the prediction for what y should be. \n", "# they may be helpful if you want to understand more about what a model is doing\n", "preds = lr.predict(X_test)\n", "\n", "lr.score(X_test, y_test)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["We need to figure out if this score is good or bad. If you followed along from the start, you might recall that the approval rate in our data was about 0.43 as well. \n", "\n", "This suggests the possibility that ``lr`` is predicting ``True`` no matter what. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["preds.all() # this tests whether all the predictions are True"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["So it turns out that ``lr`` doesn't work very well. In fact, if we had a model that guessed ``False`` all the time, that the loan would not be approved, it would have an accuracy of 0.57!"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["We can likely improve upon this baseline. In the next **Your Turn** we will ask you to explore some of the ways in which might improve the classification performance. "]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### <span style=\"color:red\">Your Turn, Feature Selection</span>"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["**Do not uncomment the following line of code. Make Sure to run the following line of code as is.** This tells the plugin that you have reached the stage where you are starting to build models. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"deletable": false, "editable": false}, "outputs": [], "source": ["# %prompter_plugin model_training%"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["Executing this block does not prevent you from changing anything you did in sections 1 and 2.\n", "\n", "Use the data you cleaned up in section 2 to build your own Logistic Regression. In the regression we built in the example above, we just used a few columns. Try different combinations of columns to see if that changes the results you get. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def choose_columns(cleaned_data):\n", "    # write code here\n", "    return cleaned_data\n", "\n", "X = choose_columns(cleaned_data)\n", "y = cleaned_data[\"approved\"] # change this if you've renamed the `approved` column\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n", "lr = LogisticRegression()\n", "lr.fit(X_train,y_train)\n", "lr.score(X_test, y_test)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### Model Selection\n", "\n", "You can also try changing the type of model that you're using. In the example above, we just used the LogisticRegression classifier. Do you get different results if you use a different type of classifier?\n", "\n", "There are other types of classifiers in scikit-learn, like the KNeighborsClassifier, or the DecisionTreeClassifier. If you are not familiar with these, don't worry. They all may be trained using the same calls to ``fit``, ``score`` and ``predict``."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "\n", "dt = DecisionTreeClassifier()\n", "knn = KNeighborsClassifier()\n", "lr = LogisticRegression()\n", "\n", "X = choose_columns(cleaned_data)\n", "y = cleaned_data[\"approved\"]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n", "\n", "dt.fit(X_train, y_train)\n", "knn.fit(X_train, y_train)\n", "lr.fit(X_train, y_train)\n", "\n", "print(lr.score(X_test, y_test), dt.score(X_test, y_test), knn.score(X_test, y_test))"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["### <span style=\"color:red\">Your Turn, Model Selection</span>\n", "\n", "Use the data and features you selected in the previous sections to train different types of models. You may use any scikit-learn model you see fit. If you think it might be useful, you can also try different parameters for different models. If you don't know what a model parameter is, or what the model parameter means, you don't need to worry about that."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# these are some examples of classifiers from the scikit-learn library\n", "\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "\n", "classifiers = [\n", "    # put classifiers here\n", "]\n", "\n", "X = choose_columns(cleaned_data)\n", "y = cleaned_data[\"approved\"]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n", "\n", "trained_clfs = [clf.fit(X_train, y_train) for clf in classifiers]\n", "scores = [clf.score(X_test, y_test) for clf in trained_clfs]\n", "\n", "print(scores)"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["# End\n", "\n", "Thank you for participating in the study. In section 3 you should have explored the performance of several different classifiers. Now is the time where you need to choose which one you believe to be the best. To submit your model for consideration, please assign your model to the variable SUBMITTED_MODEL in the cell below. Then execute the submission cell below that one. \n", "\n", "Remember that the model you submit will be used to recommend financial products to prospective loan applicants. \n", "\n", "You may submit multiple times, however only your last submitted model will be considered."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SUBMITTED_MODEL = # write the variable here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# %prompter_plugin submit %"]}, {"cell_type": "markdown", "metadata": {"trusted": true, "editable": false, "deletable": false}, "source": ["You may now return to the Qualtrics and complete the survey."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.0"}}, "nbformat": 4, "nbformat_minor": 4}