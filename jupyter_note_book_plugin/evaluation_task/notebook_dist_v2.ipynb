{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "new_section": "intro_start",
    "section": "intro"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Thank you for agreeing to take part in this evaluation. During this evaluation you will be asked to carry out a series of tasks related to the dataset shown in the next section. Please carry out these tasks with the same care and rigor as if these tasks were part of your job duties.\n",
    "    \n",
    "Before beginning please ensure that you are using the prompter kernel by looking at the top right of this notebook. It should say \"prompter\", rather than \"Python 3\". If says you are using a python kernel, please click on where it says Python, and select the prompter from the drop down study. If you encounter any errors, or if it says \"No Kernel!\" please contact [retrograde-plugin@uchicago.edu](retrograde-plugin@uchicago.edu) so we can fix the issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "## Task Description\n",
    "\n",
    "This task is structured into five parts.\n",
    "\n",
    "1. [**Data Exploration**](#data-expl)\n",
    "2. [**Data Cleaning**](#data-clean)\n",
    "3. [**Feature Creation and Feature Selection (Feature Engineering)**](#feat-eng)\n",
    "4. [**Model Training**](#model-train)\n",
    "5. [**Model Selection**](#model-select)\n",
    "\n",
    "In each of these five sections, there is an explanation/example portion and a task portion.\n",
    "The explanations are meant to provide background and structure to the task, and may be helpful to you when completing the tasks.\n",
    "You will know that you have reached a task portion because we will mark them <span style=\"color:red\"> **in red** </span>\n",
    "\n",
    "*If at any point throughout working on the task you feel the need to revisit and revise your work on a particular section, feel free to do so.*\n",
    "\n",
    "For some sections, there may be some code pre-written. This code is meant to help you complete the task by providing structure, but you are not required to use the provided code if you do not want to. You may refer to any documentation source or question asking/answering forum you like during this task (such as StackOverflow, or Pandas API documentation) we ask that you list the sources you used in the [**references**](#ref) section below. \n",
    "\n",
    "We ask that you use pandas and scikit-learn to perform the tasks. We have also installed numpy and matplotlib, should those be helpful. You will not be able to install any other non-standard libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "*(double click this cell to edit)*\n",
    "- ex: https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "new_section": "tutorial_start",
    "section": "intro",
    "tags": []
   },
   "source": [
    "## 1. Data Exploration <a class=\"anchor\" id=\"data-expl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "We will be asking you to use the provided \"loan_data.csv\" dataset during this experiment. This data was collected in a major metropolitan city in the United States. It contains information about applications for loans recieved by several different loan providers. \n",
    "\n",
    "**Your goal is to build a machine learning model capable of giving good recommendations for granting/approving loans.**\n",
    "\n",
    "Let's start trying to understand the dataset by writing some python code. Feel free to follow along by running the following sample commands in this notebook.  \n",
    "\n",
    "Below is a few lines of python code that loads the provided \"loan_data.csv\" dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "section": "intro"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# What each of these columns represents is explained below. This dictionary tells pandas what \n",
    "# data type each of the columns should be treated as.\n",
    "\n",
    "column_types = {\n",
    "    \"race\" : \"category\",\n",
    "    \"gender\" : \"category\",\n",
    "    \"zip\" : \"category\",\n",
    "    \"income\" : float,\n",
    "    \"type\" : \"category\",\n",
    "    \"term\" : int,\n",
    "    \"interest\" : float,\n",
    "    \"principal\" : int,\n",
    "    \"approved\" : bool,\n",
    "    \"adj_bls_2\" : float,\n",
    "    \"id\" : str,\n",
    "}\n",
    "\n",
    "loans = pd.read_csv(\"loan_data.csv\", parse_dates=[\"date\"], dtype=column_types)\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "We can get a list of the columns in this dataframe with the following command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "Let's look at some of the columns in the dataframe. The column ``approved`` indicates whether or not the loan was approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "section": "intro"
   },
   "outputs": [],
   "source": [
    "# since python treats True as a 1, and False as a 0, the sum\n",
    "# of this array is the number of entries in loans where approved == True\n",
    "\n",
    "print(f'{sum(loans[\"approved\"])/len(loans[\"approved\"])*100:.2f}% of loans were approved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:red\">Your Turn, Data Exploration</span>\n",
    "\n",
    "Section 1 is just an introduction to the dataset you will be using. There's no specific task for you to do in this section, however you are responsible for understanding what the columns in this dataset are representing and developing an intuition for which of those may be helpful for your model.\n",
    "\n",
    "In the next section ([**data cleaning**](#data-clean)), you will be asked to make certain decisions about how to clean this data and get it into a usable form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you are feeling unsure of where to start try some of these** (each have a link to the official documentation):\n",
    "\n",
    "*Assuming your dataframe is in the variable `df`*\n",
    "- [`df.describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html?highlight=describe#pandas-dataframe-describe)\n",
    "    - use the `include='all'` parameter to include non-numeric columns in this output\n",
    "- [`df['column_name'].quantile(0.25)`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html?highlight=quantile#pandas-dataframe-quantile)\n",
    "- [`df['column_name'].unique()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html?highlight=unique#pandas-series-unique)\n",
    "- [`df['column_name'].value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html?highlight=value_count#pandas-series-value-counts)\n",
    "\n",
    "- Using pandas to understand different intersections of your data:\n",
    "```python\n",
    "    # boolean indexing with multiple columns \n",
    "    subset = (df['column_name'] == some_val) & (df['different_col'] == different_val)\n",
    "    print(df[subset].head())\n",
    "    print(df[subset].describe())\n",
    "    # you have a subset of the original dataframe on \n",
    "    # ['column_name'] == some_val \n",
    "    # and ['different_col'] == different_val\n",
    "```\n",
    "\n",
    "Additionally, here are some brainstorming questions that you could try to explore in this section:\n",
    "- *Do certain `types` of loans get approved more frequently?*\n",
    "- *Is `income` data distributed in any notable way?*\n",
    "- *Does `approval` rate change over time?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration (feel free to create cells here as needed)\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:orange\">You should return to the Qualtrics and complete the questions for this section when you move forward.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "new_section": "null_clean_start",
    "section": "intro",
    "tags": []
   },
   "source": [
    "## 2. Data Cleaning <a class=\"anchor\" id=\"data-clean\"></a>\n",
    "\n",
    "Before we can use this data to build a model, we'll need to clean it up a bit. Raw data often will have incomplete or inaccurate records present due to entry errors, inconsistent practices in data collection and many other reasons. The way this \"dirtyness\" will manifest is often **unknown without inspection** and is different for every dataset. \n",
    "\n",
    "It is a vital part of the data scientist role **to clean and standardize** the data used and so too will it be vital for you in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "Ideally throughout the data exploration section you identified some of these signs of \"dirtyness\", but if you have not yet identified any, your first step here should be to identify the manner(s) of dirtyness present in your data. Once you have done that it will be up to you to decide how you will **clean** the data. We recommend experimenting with several methods and deciding which method(s) best achieve your goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro",
    "tags": []
   },
   "source": [
    "### <span style=\"color:red\">Your Turn, Data Cleaning</span>\n",
    "\n",
    "*If at any point throughout working on the task you feel the need to revisit and revise your work on a previous section, feel free to do so.*\n",
    "\n",
    "**Remember**, when completing the tasks try to treat them as if they are part of your job, and it is your responsibility to create an effective model for predicting loan acceptance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "section": "intro",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Cleaning (feel free to create cells here as needed)\n",
    "# Below is a small code snippet to help you get started. \n",
    "# You may delete the snippet if you wish.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def clean_data(loans_dataframe):\n",
    "    '''function for cleaning '''\n",
    "    \n",
    "    return loans_dataframe # some clean dataframe\n",
    "        \n",
    "cleaned_data = clean_data(pd.read_csv(\"loan_data.csv\", parse_dates=[\"date\"], dtype=column_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:orange\">You should return to the Qualtrics and complete the questions for this section when you move forward.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Feature Creation and Selection (Feature Engineering) <a class=\"anchor\" id=\"feat-eng\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering is a process that involves you—a data scientist—using domain knowledge to extract notable features from the raw data. In this section you will be doing just that for the data from \"loan_data.csv\". Given that you are not expected to be an expert on loan decision, use your best judgement and focus on the columns you think will help your model the most, also recall that data science is a cyclical process and it is normal to return to feature engineering in order to add and remove features after training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are unsure of where to start try these common methods:\n",
    "- Normalizing/Scaling data (try [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html))\n",
    "- Encoding categorical variables, one common way is one-hot encoding (try [`pd.get_dummies()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html#pandas-get-dummies) or [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder))\n",
    "- Grouping/Clustering/Binning of values ([`KBinsDiscretizer`](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization.html))\n",
    "\n",
    "As with previous sections, this is by no means an exhaustive list, just some simple things to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Your Turn, Feature Engineering</span>\n",
    "\n",
    "*If at any point throughout working on the task you feel the need to revisit and revise your work on a previous section, feel free to do so.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (feel free to create cells here as needed)\n",
    "# Below is a small code snippet to help you get started. \n",
    "# You may delete the snippet if you wish.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_features(data):\n",
    "    '''\n",
    "    function for creating and selecting features from your data\n",
    "    '''\n",
    "    col_list = ['income', 'principal']\n",
    "    fake_data = np.random.randint(5,30,size=len(clean_data)) # this is fake data, only used for example\n",
    "    new_feature = pd.DataFrame(fake_data, columns=[\"new_feature\"])\n",
    "    \n",
    "    features = data[col_list]\n",
    "    \n",
    "    return pd.concat([features, new_feature], axis=1)\n",
    "        \n",
    "X = get_features(cleaned_data)\n",
    "y = cleaned_data['approved']\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:orange\">You should return to the Qualtrics and complete the questions for this section when you move forward.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "new_section": "model_start",
    "section": "intro"
   },
   "source": [
    "## 4. Model Training <a class=\"anchor\" id=\"model-train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "In this section, we ask you to train a classifier which predicts whether a loan will be approved or not. The purpose of this classifier is to be used by loan officers to recommend to applicants specific loans they might be eligible for.\n",
    "\n",
    "Using the features you selected in the previous section, you will be asked to train a model that will give you a baseline level of performance to improve upon in the following [**model selection**](#model-select) section. Recall that revisiting you may revisit prior sections as necessary. \n",
    "\n",
    "A small example using the [`DummyClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) is included below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "section": "intro"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_num = loans[[\"principal\", \"interest\"]] # these columns are numeric\n",
    "\n",
    "# since loan type is a categorical variable, we need to encode it numerically\n",
    "# this creates three columns of 0/1 denoting the type of loan each row is\n",
    "X_cat = pd.get_dummies(loans[\"type\"], prefix=\"type\")\n",
    "\n",
    "example_X = pd.concat([X_num, X_cat], axis=1) # this combines the categorical and numeric columns back into 1 dataframe\n",
    "example_y = loans[\"approved\"]\n",
    "\n",
    "# this creates training and testing sets \n",
    "ex_X_train, ex_X_test, ex_y_train, ex_y_test = train_test_split(example_X, example_y, test_size=0.2, random_state=10)\n",
    "\n",
    "# dummy classifier guesses randomly at the labels\n",
    "clf = DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "# this \"fits\" or \"trains\" the model using \n",
    "# example_X and example_y as training data\n",
    "clf.fit(ex_X_train,ex_y_train) \n",
    "\n",
    "# these are the predictions for what y should be. \n",
    "# they may be helpful if you want to understand more about what a model is doing\n",
    "# since they are given on a row by row basis.\n",
    "preds = clf.predict(ex_X_test)\n",
    "\n",
    "clf.score(ex_X_test, ex_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "This is a pretty weak baseline that you can likely improve upon. In the next **Your Turn** we will ask you to explore some of the ways you might improve the classification performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:red\">Your Turn, Model Training</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro",
    "tags": []
   },
   "source": [
    "Use the data you cleaned up in [**the data cleaning section**](#data-clean) to build your own Logistic Regression. In the regression we built in the example above, we just used a few columns. Try different combinations of columns to see if that changes the results you get. \n",
    "\n",
    "Use the features you selected in the [**feature engineering**](#feat-eng) section to train a model. Experiment with one model here to get a baseline measure of the model's performance with this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not know which classifier to use, refer to this extensive [list](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) from the docs or expand the output from the cell below.\n",
    "\n",
    "Also recall every model from `sklearn` is trained and tested like so:\n",
    "```python\n",
    "# 0. initialize model\n",
    "model = MachineLearningModel()\n",
    "# 1. fit\n",
    "model.fit(training_data)\n",
    "# 2. predict\n",
    "predictions = model.predict(test_data)\n",
    "# 3. score\n",
    "model.score(test_data, test_labels)\n",
    "```\n",
    "\n",
    "*If at any point throughout working on the task you feel the need to revisit and revise your work on a previous section, feel free to do so.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n",
      "BaggingClassifier\n",
      "BayesianGaussianMixture\n",
      "BernoulliNB\n",
      "CalibratedClassifierCV\n",
      "CategoricalNB\n",
      "ClassifierChain\n",
      "ComplementNB\n",
      "DecisionTreeClassifier\n",
      "DummyClassifier\n",
      "ExtraTreeClassifier\n",
      "ExtraTreesClassifier\n",
      "GaussianMixture\n",
      "GaussianNB\n",
      "GaussianProcessClassifier\n",
      "GradientBoostingClassifier\n",
      "GridSearchCV\n",
      "HalvingGridSearchCV\n",
      "HalvingRandomSearchCV\n",
      "HistGradientBoostingClassifier\n",
      "KNeighborsClassifier\n",
      "LabelPropagation\n",
      "LabelSpreading\n",
      "LinearDiscriminantAnalysis\n",
      "LogisticRegression\n",
      "LogisticRegressionCV\n",
      "MLPClassifier\n",
      "MultiOutputClassifier\n",
      "MultinomialNB\n",
      "NuSVC\n",
      "OneVsRestClassifier\n",
      "Pipeline\n",
      "QuadraticDiscriminantAnalysis\n",
      "RFE\n",
      "RFECV\n",
      "RadiusNeighborsClassifier\n",
      "RandomForestClassifier\n",
      "RandomizedSearchCV\n",
      "SGDClassifier\n",
      "SVC\n",
      "SelfTrainingClassifier\n",
      "StackingClassifier\n",
      "VotingClassifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import all_estimators\n",
    "\n",
    "estimators = all_estimators()\n",
    "\n",
    "for name, class_ in estimators:\n",
    "    if hasattr(class_, 'predict_proba'):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "section": "intro"
   },
   "outputs": [],
   "source": [
    "# Model Training (feel free to create cells here as needed)\n",
    "# Below is a small code snippet to help you get started. \n",
    "# You may delete the snippet if you wish.\n",
    "\n",
    "# import a machine learning model here\n",
    "\n",
    "X = get_features(cleaned_data)\n",
    "y = cleaned_data[\"approved\"] # you are predicting the \"approved\" column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:orange\">You should return to the Qualtrics and complete the questions for this section when you move forward.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro",
    "tags": []
   },
   "source": [
    "## 5. Model Selection <a class=\"anchor\" id=\"model-select\"></a>\n",
    "\n",
    "You can also try changing the type of model that you're using. In the example above, you used one type of classifier. Different classifier models will give you different performance and different results. Additionally you may consider tuning some of the hyperparameters of the model to achieve the results you want.\n",
    "\n",
    "If you are not familiar with these different models, don't worry. They all may be trained and tested using the same calls to ``fit``, ``score`` and ``predict``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:red\">Your Turn, Model Selection</span>\n",
    "\n",
    "Use the data and features you selected in the previous sections to train different types of models. You may use any scikit-learn model you see fit and any method of model evaluation/selection available to you. \n",
    "\n",
    "If you think it might be useful, you can also try different hyperparameters for different models or any other method of evaluating/improving a model available. If you don't know what a model parameter is, or what the model parameter means, don't need to worry about it as it is not required to use these hyperparamters.\n",
    "\n",
    "*If at any point throughout working on the task you feel the need to revisit and revise your work on a previous section, feel free to do so.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "section": "intro",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Selection (feel free to create cells here as needed)\n",
    "# Below is a small code snippet to help you get started. \n",
    "# You may delete the snippet if you wish.\n",
    "\n",
    "# import more models here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = get_features(cleaned_data)\n",
    "y = cleaned_data[\"approved\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# put models here \n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:orange\">You should return to the Qualtrics and complete the questions for this section when you move forward.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "new_section": "end_start",
    "section": "intro",
    "tags": []
   },
   "source": [
    "# End\n",
    "\n",
    "Thank you for participating in the study. In [**model selection**](#model-select) you should have explored the performance of several different classifiers. Now is the time where you need to choose which one you believe to be the best. To submit your model for consideration, please assign your model to the variable SUBMITTED_MODEL in the cell below and then execute the cell.\n",
    "\n",
    "Remember that the model you submit will be used to recommend financial products to prospective loan applicants. \n",
    "\n",
    "You may submit multiple times, however only your last submitted model will be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "section": "intro"
   },
   "outputs": [],
   "source": [
    "SUBMITTED_MODEL = # write the variable here\n",
    "\n",
    "# if the model you decide on is named clf, then you would write \n",
    "# SUBMITTED_MODEL = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "section": "intro"
   },
   "source": [
    "### <span style=\"color:orange\">If you have ran the above cell you may now return to the Qualtrics and complete the survey.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
