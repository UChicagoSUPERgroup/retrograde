{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c81d35d5-f9d1-46ea-a219-c4c3a8b862a3",
   "metadata": {
    "section": "intro",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def permute_data(data, one_hot_cols):\n",
    "    \"\"\"\n",
    "    for each row, choose a column unif. at random and change a value\n",
    "    \"\"\"\n",
    "    all_one_hot = [c for col_set in one_hot_cols for c in col_set]\n",
    "    normal_cols = [c for c in data.columns if c not in all_one_hot]\n",
    "    \n",
    "    def permute_row(row):\n",
    "        # choose which column\n",
    "        chosen = np.random.choice(len(normal_cols)+len(one_hot_cols))\n",
    "        if chosen < len(normal_cols):\n",
    "            col = normal_cols[chosen]\n",
    "            row[col] = np.random.choice(data[col])\n",
    "        else:\n",
    "                        \n",
    "            col = one_hot_cols[chosen-len(normal_cols)]\n",
    "            counts = data[col].sum(axis=0)\n",
    "            \n",
    "            # may be dummy coded with reference class = 0\n",
    "            if counts.sum() == len(data):\n",
    "                probs = counts/len(data)\n",
    "                col_choice = np.random.choice(col, p=probs)\n",
    "            \n",
    "                row[col] = 0\n",
    "                row[col_choice] = 1.0\n",
    "            else:\n",
    "                counts = list(counts) + [len(data) - counts.sum()]\n",
    "                probs = np.array(counts)/len(data)\n",
    "                \n",
    "                col_choices = col + [None]\n",
    "                col_choice = np.random.choice(col_choices, p=probs)\n",
    "                \n",
    "                row[col] = 0\n",
    "                \n",
    "                if col_choice is not None:\n",
    "                    row[col_choice] = 1.0\n",
    "                \n",
    "        return row\n",
    "    return data.apply(permute_row, axis=1)\n",
    "\n",
    "def test_data_perturb(model, input_features, one_hot_cols, n_tests=10):\n",
    "    \"\"\"\n",
    "    resample the data n_tests times and return the true->false and false->true\n",
    "    \n",
    "    assume labels are true/false\n",
    "    \n",
    "    one_hot_cols is a (possibly empty) list of lists of columns that are one-hot encoded\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = model.predict(input_features)\n",
    "    false_to_true = 0\n",
    "    true_to_false = 0\n",
    "    \n",
    "    for _ in range(n_tests):\n",
    "        \n",
    "        shuff_data = permute_data(input_features, one_hot_cols)\n",
    "        shuff_preds = model.predict(shuff_data)\n",
    "        \n",
    "        false_to_true += (~preds & shuff_preds).sum()\n",
    "        true_to_false += (preds & ~ shuff_preds).sum()\n",
    "        \n",
    "    return false_to_true/(n_tests*len(preds)), true_to_false/(n_tests*len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbffba0c-e06f-498f-b00b-2b132802e2d1",
   "metadata": {
    "section": "intro"
   },
   "outputs": [],
   "source": [
    "def make_metrics(true,preds):\n",
    "    \n",
    "    fp = (~true & preds).sum()\n",
    "    tn = (~true & ~preds).sum()\n",
    "    tp = (true & preds).sum()\n",
    "    fn = (true & ~preds).sum()\n",
    "    \n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    fpr = fp/(fp+tn)\n",
    "    fnr = fn/(tp+fn)\n",
    "    f1 = 2*(precision*recall)/(precision + recall)\n",
    "    \n",
    "    return precision, recall, fpr, fnr, f1\n",
    "\n",
    "def make_model_report(data, true, preds):\n",
    "    \"\"\"\n",
    "    do report for values \n",
    "    \"\"\"\n",
    "    \n",
    "    # precision\n",
    "    # recall\n",
    "    # FPR\n",
    "    # FNR\n",
    "    # F1\n",
    "    \n",
    "    precision, recall, fpr, fnr, f1 = make_metrics(true, preds)\n",
    "    \n",
    "    print(f\"\"\"Overall\n",
    "        precsion = {precision}\n",
    "        recall =  {recall}\n",
    "        fpr = {fpr}\n",
    "        fnr = {fnr}\n",
    "        f1 = {f1}\n",
    "    \"\"\")\n",
    "    \n",
    "    for col in [\"race\", \"gender\"]:\n",
    "        \n",
    "        scores = {\"precision\" : [],\n",
    "                  \"recall\" : [],\n",
    "                  \"fpr\" : [],\n",
    "                  \"fnr\" : [],\n",
    "                  \"f1\" : []}\n",
    "        \n",
    "        for val in data[col].unique():\n",
    "            \n",
    "            subset = data[col] == val\n",
    "            precision, recall, fpr, fnr, f1 = make_metrics(true[subset], preds[subset])\n",
    "            \n",
    "            scores[\"precision\"].append((precision, val))\n",
    "            scores[\"recall\"].append((recall, val))\n",
    "            scores[\"fpr\"].append((fpr, val))\n",
    "            scores[\"fnr\"].append((fnr, val))\n",
    "            scores[\"f1\"].append((f1, val))\n",
    "        \n",
    "        print(f\"For column {col}\")\n",
    "        for k in scores:\n",
    "            \n",
    "            max_tuple = max(scores[k], key=lambda x: x[0])\n",
    "            min_tuple = min(scores[k], key=lambda x: x[0])\n",
    "            \n",
    "            print(f\"Max {k}, {max_tuple[0]}, {max_tuple[1]}\")\n",
    "            print(f\"Min {k}, {min_tuple[0]}, {min_tuple[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616d4038-0a36-494f-bc3a-7f4390a532ea",
   "metadata": {
    "section": "intro"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_types = {\n",
    "    \"race\" : \"category\",\n",
    "    \"gender\" : \"category\",\n",
    "    \"zip\" : \"category\",\n",
    "    \"income\" : float,\n",
    "    \"type\" : \"category\",\n",
    "    \"interest\" : float,\n",
    "    \"term\" : float,\n",
    "    \"principal\" : float,\n",
    "    \"approved\" : bool,\n",
    "    \"adj_bls_2\" : float,\n",
    "    \"id\" : str,\n",
    "}\n",
    "data = pd.read_csv(\"./clean_data.csv\", dtype=column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b198285-587d-45ea-bbf0-854b10fd0692",
   "metadata": {
    "section": "intro"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "X = data[[\"income\", \"interest\", \"term\", \"adj_bls_2\"]]\n",
    "X_cat = pd.get_dummies(data[\"type\"], drop_first=True) \n",
    "X_gend = pd.get_dummies(data[\"gender\"])\n",
    "X = pd.concat([X, X_cat, X_gend], axis=1)\n",
    "y = data[\"approved\"]\n",
    "\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a7d5cb4-9b66-4a40-9e43-f344b7ec4d40",
   "metadata": {
    "section": "intro"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.061375, 0.04783333333333333)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_perturb(lr, X, [[\"home\", \"personal\"], [\"female\", \"male\", \"non-binary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0064b0dd-3bbf-4d89-80a9-dbfa67738177",
   "metadata": {
    "section": "intro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall\n",
      "        precsion = 0.573109243697479\n",
      "        recall =  0.4030732860520095\n",
      "        fpr = 0.16344916344916344\n",
      "        fnr = 0.5969267139479906\n",
      "        f1 = 0.4732824427480916\n",
      "    \n",
      "For column race\n",
      "Max precision, 0.6907216494845361, white\n",
      "Min precision, 0.28846153846153844, black\n",
      "Max recall, 0.5153846153846153, white\n",
      "Min recall, 0.23076923076923078, black\n",
      "Max fpr, 0.32653061224489793, asian\n",
      "Min fpr, 0.10855263157894737, hispanic/latino\n",
      "Max fnr, 0.7692307692307693, black\n",
      "Min fnr, 0.4846153846153846, white\n",
      "Max f1, 0.5903083700440528, white\n",
      "Min f1, 0.25641025641025644, black\n",
      "For column gender\n",
      "Max precision, 1.0, non-binary\n",
      "Min precision, 0.5606060606060606, female\n",
      "Max recall, 0.43953488372093025, male\n",
      "Min recall, 0.3645320197044335, female\n",
      "Max fpr, 0.18351063829787234, male\n",
      "Min fpr, 0.0, non-binary\n",
      "Max fnr, 0.6354679802955665, female\n",
      "Min fnr, 0.5604651162790698, male\n",
      "Max f1, 0.5714285714285715, non-binary\n",
      "Min f1, 0.4417910447761194, female\n"
     ]
    }
   ],
   "source": [
    "preds = lr.predict(X)\n",
    "make_model_report(data, y, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrograde",
   "language": "",
   "name": "prompt_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
